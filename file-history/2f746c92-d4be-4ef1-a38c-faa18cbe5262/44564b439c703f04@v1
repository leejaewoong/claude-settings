# 크롤러 설정 및 실행 가이드

## 개요
이 프로젝트는 네이버 카페 게시글을 3시간마다 자동으로 수집하여 데이터베이스에 저장합니다.

## 구성 요소

### 1. 크롤러 (Crawler)
- **파일**: `app/services/naver_cafe_crawler.py`
- **기능**: 네이버 카페에서 게시글과 댓글을 크롤링
- **특징**:
  - Playwright를 사용한 브라우저 자동화
  - 모바일 User Agent 사용
  - 게시글 제목, 내용, 댓글, 작성자 정보 수집
  - 중복 방지를 위한 external_id 생성

### 2. DB 저장 (Database Service)
- **파일**: `app/services/post_service.py`
- **기능**: 크롤링한 데이터를 데이터베이스에 저장
- **특징**:
  - Upsert 방식으로 중복 방지
  - SQLite/PostgreSQL 지원
  - 댓글을 JSON 형태로 저장

### 3. Celery 스케줄러 (Task Scheduler)
- **파일**: `app/celery_app.py`, `app/tasks/crawler_tasks.py`
- **기능**: 3시간마다 자동으로 크롤링 실행
- **스케줄**: 3시간 (10,800초)

## 실행 방법

### 1. 필수 패키지 설치
```bash
cd backend
pip install -r requirements.txt
python -m playwright install chromium
```

### 2. 데이터베이스 초기화
```bash
python init_db.py
```

### 3. Redis 실행 (Celery용)
```bash
# Docker 사용 시
docker run -d -p 6379:6379 redis:latest

# 또는 로컬 Redis 설치 및 실행
redis-server
```

### 4. Celery Worker 실행
```bash
celery -A app.celery_app worker --loglevel=info
```

### 5. Celery Beat 실행 (스케줄러)
```bash
celery -A app.celery_app beat --loglevel=info
```

### 6. FastAPI 서버 실행
```bash
uvicorn app.main:app --reload
```

## 수동 크롤링 실행

### API를 통한 수동 실행
```bash
curl -X POST http://localhost:8000/api/crawler/run/naver-cafe
```

### 테스트 스크립트 실행
```bash
# DB 저장만 테스트
python test_db_only.py

# 전체 크롤링 및 DB 저장 테스트
python test_crawl_and_save.py
```

## 설정

### 환경 변수 (.env)
```env
# Database
DATABASE_URL=sqlite+aiosqlite:///./data.db

# Celery
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1
```

### 크롤링 대상 메뉴 변경
`app/services/naver_cafe_crawler.py` 파일에서 `crawl_all_menus()` 메서드의 `target_menus` 리스트를 수정:
```python
target_menus = [1, 177, 107, 28]  # 원하는 메뉴 ID로 변경
```

## 구조

```
backend/
├── app/
│   ├── api/
│   │   └── crawler.py          # 크롤러 API 엔드포인트
│   ├── services/
│   │   ├── naver_cafe_crawler.py  # 크롤러 구현
│   │   └── post_service.py        # DB 저장 서비스
│   ├── tasks/
│   │   └── crawler_tasks.py    # Celery 태스크 정의
│   ├── models/
│   │   └── post.py             # Post 모델
│   ├── celery_app.py           # Celery 설정
│   └── main.py                 # FastAPI 앱
├── init_db.py                  # DB 초기화 스크립트
├── test_db_only.py             # DB 테스트 스크립트
└── test_crawl_and_save.py      # 전체 테스트 스크립트
```

## 데이터 모델

### Post (게시글)
- `id`: 자동 증가 ID
- `source`: 출처 (예: "naver_cafe")
- `external_id`: 외부 ID (중복 방지용, unique)
- `title`: 제목
- `content`: 내용
- `url`: 원본 URL
- `author`: 작성자
- `created_at`: 작성 시간
- `collected_at`: 수집 시간
- `comments`: 댓글 (JSON 배열)

## 모니터링

### Celery Flower (선택사항)
```bash
pip install flower
celery -A app.celery_app flower
# http://localhost:5555 에서 확인
```

### 로그 확인
- Celery Worker: 콘솔에서 실시간 확인
- Celery Beat: 콘솔에서 스케줄 실행 확인
- FastAPI: `uvicorn` 로그 확인

## 트러블슈팅

### 크롤러가 내용을 가져오지 못할 때
- 네이버 카페의 구조가 변경되었을 수 있습니다
- `naver_cafe_crawler.py`의 CSS 셀렉터를 업데이트해야 합니다
- 브라우저 개발자 도구로 실제 HTML 구조를 확인하세요

### Redis 연결 오류
```bash
# Redis가 실행 중인지 확인
redis-cli ping
# 응답: PONG
```

### Celery Task가 실행되지 않을 때
1. Celery Worker가 실행 중인지 확인
2. Celery Beat가 실행 중인지 확인
3. Redis 연결 확인
4. 스케줄 설정 확인: `celery -A app.celery_app inspect scheduled`

## 현재 알려진 이슈

1. **크롤러 셀렉터 문제**: 네이버 카페의 모바일 뷰에서 일부 게시글의 내용과 댓글을 가져오지 못하는 경우가 있습니다. 이는 네이버 카페의 구조 변경 때문일 수 있으며, 셀렉터를 업데이트해야 합니다.

2. **한글 인코딩**: Windows 콘솔에서 한글이 깨져 보일 수 있지만, 데이터베이스에는 UTF-8로 정상 저장됩니다.

## 다음 단계

1. 크롤러 셀렉터 개선 (네이버 카페 구조에 맞게 조정)
2. 에러 리포팅 (Sentry 연동)
3. 크롤링 결과 모니터링 대시보드
4. 감정 분석 및 Slack 전송 기능 추가
